{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b033d1fbb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle, importlib, random, Engine, tqdm, copy, json, time, argparse\n",
    "import util.Generator as Generator\n",
    "import util.Datahelper as dh\n",
    "\n",
    "sys.argv = ' '\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-test', action=\"store_true\", default=False)\n",
    "parser.add_argument('-ckptname', dest='ckptname', default=None, required=False)\n",
    "\n",
    "parser.add_argument('-nl', dest='num_layers', default=2, required=False)\n",
    "parser.add_argument('-nhd', dest='num_hidden_dims', default=2**9, required=False)\n",
    "parser.add_argument('-nh', dest='num_heads', default=8, required=False)\n",
    "\n",
    "parser.add_argument('-i', dest='use_item_feat', default=True, required=False)\n",
    "parser.add_argument('-u', dest='use_user_feat', default=True, required=False)\n",
    "\n",
    "parser.add_argument(\n",
    "    '-pt_sample_func', dest='pt_sample_func', default='(lambda x:x)', required=False)\n",
    "parser.add_argument(\n",
    "    '-pt_sample_param', dest='pt_sample_param', default='0', required=False)\n",
    "parser.add_argument(\n",
    "    '-pt_history_func', dest='pt_history_func', default='(lambda x:x)', required=False)\n",
    "parser.add_argument(\n",
    "    '-pt_history_param', dest='pt_history_param', default='20', required=False)\n",
    "\n",
    "parser.add_argument('-nonimprove_limit', dest='nonimprove_limit', default=10, required=False)\n",
    "parser.add_argument('-seed', dest='seed', default=0, required=False, type=int)\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "Engine.set_random_seed(args.seed)\n",
    "\n",
    "basic_config = {\n",
    "    'cuda_num' : Engine.GPU_max_free_memory(),\n",
    "    'course_file' : '../datasets/Amazon_data/Beauty/basket_dataset.pkl',\n",
    "    'num_times' : 20,\n",
    "    'num_items' : 10000, \n",
    "    'batch_size' : 32, \n",
    "    'feats' : [5]\n",
    "}\n",
    "    \n",
    "save_name = 'checkpoint/KNN'\n",
    "print(basic_config)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(basic_config['cuda_num'])\n",
    "\n",
    "with open(basic_config['course_file'], 'rb') as f:\n",
    "    user_dict = pickle.load(f)\n",
    "    print('Total Number of Users : ' + str(len(user_dict)))\n",
    "    \n",
    "all_keys = list(user_dict.keys())\n",
    "all_keys.sort()\n",
    "np.random.shuffle(all_keys)\n",
    "#used_keys, _ = dh.list_partition(all_keys, 0.1, seed=0)\n",
    "\n",
    "train_keys, tv_keys = dh.list_partition(all_keys, 0.7, seed=0)\n",
    "test_keys, valid_keys = dh.list_partition(tv_keys, 0.5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator2feature(generator):\n",
    "    dataset = generator.__getitem__(batch_id=0, batch_size='MAX')[0]\n",
    "    course = dataset[0]\n",
    "    target = dataset[-1]\n",
    "    return course, target\n",
    "\n",
    "if True:\n",
    "    train_generator_config = {\n",
    "        'name' : None,\n",
    "        'training' : True, \n",
    "        'sample_func' : args.pt_sample_func,\n",
    "        'sample_param' : args.pt_sample_param,\n",
    "        'history_func' : args.pt_history_func,\n",
    "        'history_param' : args.pt_history_param,\n",
    "        'next_basket' : True, \n",
    "        'batch_size' : basic_config['batch_size'],\n",
    "        'shuffle' : True,\n",
    "        'fixed_seed' : False}\n",
    "\n",
    "    train_generator = Generator.TimeMultihotGenerator(\n",
    "        user_dict, train_keys, basic_config, train_generator_config)\n",
    "\n",
    "train_courses, train_target = generator2feature(train_generator)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import util.Metrics as Metrics\n",
    "\n",
    "def userKNN_GPU(train_features, test_courses, cuda_num):\n",
    "    # train_features, torch.FloatTensor in GPU [num_stu, num_courses]\n",
    "    # test_courses, np.array in CPU [num_stu, num_sem, num_courses]\n",
    "    test_features = torch.FloatTensor(test_courses.sum(1).astype(float)).cuda(cuda_num)\n",
    "    #train_features += torch.rand(train_features.shape).cuda(cuda_num) * 1e-10\n",
    "    #test_features += torch.rand(test_features.shape).cuda(cuda_num) * 1e-10\n",
    "\n",
    "    sim = []\n",
    "    for iter in tqdm.tqdm(range(test_features.shape[0])):\n",
    "        sim.append(torch.cosine_similarity(train_features.unsqueeze(1), test_features[iter].unsqueeze(0).unsqueeze(0), dim=-1))\n",
    "    sim = torch.cat(sim, dim=-1).T\n",
    "\n",
    "    pred = []\n",
    "    for iter in range(basic_config['num_times']):\n",
    "        pred.append(torch.matmul(sim, torch.FloatTensor(train_courses[:, iter]).cuda(cuda_num))[:, np.newaxis])\n",
    "    pred = torch.cat(pred, dim=1)\n",
    "    #pred += torch.rand(pred.shape).cuda(cuda_num) * 1e-10\n",
    "    pred = pred.cpu().numpy()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator_config = {\n",
    "    'training' : False, \n",
    "    'max_sampling' : 6,\n",
    "    'mask_rate' : None,\n",
    "    'historical' : None,\n",
    "    'batch_size' : 16,\n",
    "    'shuffle' : False,\n",
    "    'fixed_seed' : True}\n",
    "    \n",
    "    \n",
    "results_mat = {}\n",
    "for h in list(range(4)) + list(range(5, 21, 5)):\n",
    "    results_mat[h] = {}\n",
    "    for r in list(range(6)):\n",
    "        test_generator_config['sample_func'] = '(lambda x:x)'\n",
    "        test_generator_config['sample_param'] = str(r)\n",
    "        test_generator_config['history_func'] = '(lambda x:x)'\n",
    "        test_generator_config['history_param'] = str(h)\n",
    "        test_generator_config['name'] = 'H={1}_R={0}'.format(r, h)\n",
    "        test_generator = Generator.TimeMultihotGenerator(\n",
    "            user_dict, test_keys, basic_config, test_generator_config)\n",
    "        \n",
    "        print(test_generator.name + ' ' + str(test_generator.batch_size))\n",
    "        train_features = torch.FloatTensor(train_courses.sum(1).astype(float))\n",
    "        train_features_cuda = train_features.cuda(basic_config['cuda_num'])\n",
    "        test_courses, test_target = generator2feature(test_generator)\n",
    "        user_pred = userKNN_GPU(train_features_cuda, test_courses, basic_config['cuda_num'])\n",
    "        recall, recall_per_sem = Metrics.recall(test_target[:, h:], user_pred[:, h:], at_n=10)\n",
    "        print('Recall: {:.4f}'.format(recall))\n",
    "        results_mat[h][r] = [recall, recall_per_sem]\n",
    "save_name = save_name + '.npy'\n",
    "print(save_name)\n",
    "np.save(save_name, np.array(results_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
